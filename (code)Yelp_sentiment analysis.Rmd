---
title: "text mining"
author: "Evelyn Huang"
date: "11/1/2021"
output: html_document
---

```{r}
library('tidyverse')
install.packages("tidytext")
install.packages("SnowballC")
install.packages("textstem")
library(tidytext)
library(SnowballC)
library(textstem)
library(ranger)
library(e1071)
install.packages("textdata")
library(textdata)

resReviewsData <- read_csv2('yelpRestaurantReviews_sample_s21b.csv')

```



```{r}
#number of reviews by star-rating
resReviewsData %>% group_by(starsReview) %>% count() %>% view()

funny_star <- ggplot(resReviewsData, aes(x= funny, y=starsReview)) +geom_point()
useful_star <- ggplot(resReviewsData, aes(x= useful, y=starsReview)) +geom_point()
cool_star <-  ggplot(resReviewsData, aes(x= cool, y=starsReview)) +geom_point()

cool_funny <-  ggplot(resReviewsData, aes(x= cool, y=funny)) +geom_point()
cool_useful <-  ggplot(resReviewsData, aes(x= cool, y=useful)) +geom_point()
useful_funny <-  ggplot(resReviewsData, aes(x= useful, y=funny)) +geom_point()

```

```{r pressure, echo=FALSE}
plot(funny_star)
```


```{r pressure, echo=FALSE}
plot(useful_star)
```


```{r pressure, echo=FALSE}
plot(cool_star)
```
```{r pressure, echo=FALSE}
plot(cool_funny)
```
```{r pressure, echo=FALSE}
plot(cool_useful)
```
```{r pressure, echo=FALSE}
plot(useful_funny)
```

\#How does star ratings for reviews relate to the star-rating given in the dataset for businesse (attribute ‘businessStars’)? (Can one be calculated from the other?)
```{r pressure, echo=FALSE}

rest_star<- resReviewsData %>% select(c(review_id, starsReview,name, starsBusiness))
rest_star%>% group_by(name) %>% summarise(avgstar=mean(starsReview),starsBusiness) %>%  tally()
rest_star%>% group_by(name) %>% tally() %>% view()
cor(resReviewsData$starsReview, resReviewsData$starsBusiness) #[1] 0.4114881
lmstars <- lm(starsBusiness ~starsReview, data =resReviewsData)
summary(lmstars)

# view it by restaurant!
rest_star%>% group_by(name) %>% tally() %>% view()
lmstars_SI <- lm(starsBusiness ~starsReview, data =resReviewsData %>% filter(name=="Sugar & Ice"))
lmstars_Alle <- lm(starsBusiness ~starsReview, data =resReviewsData %>% filter(name=="Allegro"))
lmstars_momo <- lm(starsBusiness ~starsReview, data =resReviewsData %>% filter(name=="Momo Sushi"))	
lmstars_innout <- lm(starsBusiness ~starsReview, data =resReviewsData %>% filter(name=="In-N-Out Burger"))		
lmstars_thai <- lm(starsBusiness ~starsReview, data =resReviewsData %>% filter(name=="Thai House"))		
	
summary(lmstars_Alle)
summary(lmstars_momo)
summary(lmstars_innout)
summary(lmstars_thai)


 # we can get a statistically significant linear regression for those 2 caegories of stars review

```


```{r pressure, echo=FALSE}
stars_relationship <-  ggplot(resReviewsData, aes(x= starsReview, y=starsBusiness)) + geom_count(alpha = 0.5) # geom_point()
plot(stars_relationship)
```
# Steps to prepare the data 

# consider a pruned set of terms -- say, those which occur in a certain minimum and maximum number of documents).
\# rare and freq to remove
```{r pressure, echo=FALSE}

#tokenize the text of the reviews in the column named 'text‘ - keep only the reviewID, stars attribs 
# STEP 1:  transfer Text -> Words and unnest_tokens(word, text) will by default make text into lowercase
rrTokens <- resReviewsData %>% select(review_id, starsReview, text ) %>% unnest_tokens(word, text)
dim(rrTokens) #4422210  
head(rrTokens)

#How many distinct terms?
rrTokens %>% distinct(word) %>% dim() #43993 

# STEP 2: remove stopwords
rrTokens <- rrTokens %>% anti_join(stop_words)

#count the total occurrences of different words, & sort by most frequent
rrTokens %>% count(word, sort=TRUE) %>% top_n(10)
rrTokens %>% count(word, sort=TRUE) %>% top_n(-10)

#check distribution of the n : word presents in how may review?
a=rrTokens %>% count(word, sort=TRUE) #%>% top_n(-10)
summary(a$n)
 #     Min.  1st Qu.   Median   Mean     3rd Qu.     Max. 
 #    1.00     1.00     2.00    36.32     7.00    32113.00 


# Are there some rare terms, which occur in very few reviews?
# Step3: remove rare words which are not present in at least 10 reviews
rareWords <-rrTokens %>% count(word, sort=TRUE) %>% filter(n<10) 
rareWords

# remove rare words from rrtokens
xx<-anti_join(rrTokens, rareWords)


# double check if there is something else we need to delete
xx %>% count(word, sort=TRUE) %>% view()
# remove decimal number and numbers
xx <- xx %>% filter(str_detect(word,"[0-9]") == FALSE) 
xx %>% count(word, sort=TRUE) %>% view() #check again
#confirm that you want these changes
rrTokens<- xx
#How many distinct tokens remain ?
rrTokens %>% distinct(word) %>% dim() 
   #[1] 9167

# remove too frequent words
freqWords <-rrTokens %>% count(word, sort=TRUE) %>% filter(n>8000) 
freqWords

# remove frequent words from rrtokens
xx<-anti_join(rrTokens, freqWords)

#confirm that you want these changes
rrTokens<- xx
#How many distinct tokens remain ? 
rrTokens %>% distinct(word) %>% dim() 
   #[1] 9167-> 9162 food/service/time/chicken/restaurant

```


# Words associated with different starratings
\# ...PAGE 7 on the slide
```{r}
 #Check words by star rating of reviews
rrTokens %>% group_by(word,starsReview) %>% count(word, sort=TRUE) # %>% view()

#proportion of word occurrence by star ratings
ws <- rrTokens %>% group_by(starsReview) %>% count(word, sort=TRUE) 
ws <- ws %>% group_by(starsReview) %>% mutate(prop=n/sum(n))

ws %>% filter(starsReview=="5") %>%view()
ws %>% filter(starsReview=="4") %>%view()
ws %>% filter(starsReview=="2") %>%view()
ws %>% filter(starsReview=="1") %>%view()


#check the proportion of 'love' among reviews with 1,2,..5 stars 
ws %>% filter(word=='food') %>% view()
ws %>% filter(word=='service') %>% view()
ws %>% filter(word=='time') %>% view()
ws %>% filter(word=='chicken') %>% view()
ws %>% filter(word=='restaurant') %>% view()  #we can tell words with  n>8000, are meaningless since they are basically evenly distributed among 5 stars review

ws %>% filter(word=='tasty') %>% view()
ws %>% filter(word=='eat') %>% view()



#what are the most commonly used words by star rating
ws %>% group_by(starsReview) %>% arrange(starsReview, desc(prop)) %>% view()

#to see the top 20 words by star ratings
ws %>% group_by(starsReview) %>% arrange(starsReview, desc(prop))%>% filter(row_number()<=20) %>% view()

#To plot this
ws %>% group_by(starsReview) %>% arrange(starsReview, desc(prop))%>% filter(row_number()<=10)%>% ggplot(aes(word, prop))+geom_col()+coord_flip()+facet_wrap((~starsReview))+ggtitle("Top 10 Words in Didderent Stars Review")

```



```{r pressure, echo=FALSE}
# HAVE REMOVES Frequent words: 'food', "time", 'restaurant', 'service', 'chicken'
#ws %>% filter(!word %in% c('food', "time", 'restaurant', 'service')) %>% arrange(desc(prop)) %>%filter(row_number() <=15)
ws %>% arrange(desc(prop)) %>%filter(row_number() <=15)

# plot words occurs across ratings 
ws %>%  group_by(starsReview) %>% arrange(starsReview,desc(prop)) %>%
  filter(row_number() <=15) %>% ggplot(aes(word,prop))+geom_col()+coord_flip()+facet_wrap((~starsReview))
```


```{r pressure, echo=FALSE}

ws %>% filter(starsReview==5| starsReview==4) %>% arrange(desc(prop))%>% filter(row_number()<=20)
ws %>% filter(starsReview==1| starsReview==2) %>% arrange(desc(prop))%>%filter(row_number()<=20)

```

```{r pressure, echo=FALSE}
#ws %>% filter(starsReview==5) %>% filter(row_number()<=20) %>%  ggplot(aes(word, n)) + geom_col()+coord_flip()
ws %>% filter(starsReview==5| starsReview==4) %>% filter(row_number()<=20) %>%  ggplot(aes(word, n)) + geom_col()+coord_flip()+ggtitle("Positive Review Words")
ws %>% filter(starsReview==1| starsReview==2) %>% filter(row_number()<=20) %>%  ggplot(aes(word, n)) + geom_col()+coord_flip()+ggtitle("Negative Review Words")
```

# gather some onfo from above words freq in different stars
```{r}
# ws %>% filter(word=='food') %>% view()
ws %>% filter(word=='tasty') %>% view()
# ws %>% filter(word=='service') %>% view()
ws %>% filter(word=='eat') %>% view()
```


#score: starsReview*prop
```{r}
#Can we get a sense of which words are related to higher/lower star raings in general? 
#One approach is to calculate the average star rating associated with each word - can sum the star ratings associated with reviews where each word occurs in.  Can consider the proportion of each word among reviews with a star rating.

xx<- ws %>% group_by(word) %>%summarise(totWS=sum(starsReview*prop))
# 20 words with highest and lowest star rating
xx %>% top_n(20)
xx %>% top_n(-20)

xx_neg<- ws %>% group_by(word) %>% filter(starsReview==1| starsReview==2) %>%  summarise(totWS=sum(starsReview*prop))
xx_pos<- ws %>% group_by(word) %>% filter(starsReview==4| starsReview==5) %>%  summarise(totWS=sum(starsReview*prop))

xx_neg %>% top_n(20) %>% view()
xx_neg %>% top_n(-20)

xx_pos %>% top_n(20) %>% view()
xx_pos %>% top_n(-20)
```


\# How many matching terms are there for each of the dictionaries?
\#Stemming and Lemmatization
```{r}
rrTokens_stem <- rrTokens %>% mutate(word_stem = SnowballC::wordStem(word))  # ic 結尾
rrTokens_lemm <- rrTokens %>% mutate(word_lemma = textstem::lemmatize_words(word))


#frequency
#tokenize, remove stopwords, and lemmatize
rrTokens<-rrTokens %>% mutate(word = textstem::lemmatize_words(word))

  ##   Or, can tokenize, remove stopwords, lemmatize i as
  #   rrTokens <- resReviewsData %>% select(review_id, starsReview, text )%>% unnest_tokens(word, text) %>%        
  #      anti_join(stop_words) %>% mutate(word = textstem::lemmatize_words(word))

# filter out words with less than 3 characters more than 15 characters 
rrTokens<-rrTokens %>% filter(str_length(word)<=3 | str_length(word)<=15)
#rrTokens<-rrTokens %>% filter(str_length(word)>=3 & str_length(word)<=15)

rrTokens<- rrTokens %>% group_by(review_id, starsReview) %>% count(word)

   #count total number of words by review, and add this in a column
   totWords<-rrTokens %>% group_by(review_id)%>% count(word, sort=TRUE) %>% summarise(total=sum(n))
   #add the column of counts
   xx<-left_join(rrTokens, totWords)
   # now n/total gives the tf values
   xx<- xx %>% mutate(tf=n/total) 
   head(xx)  

#### final touch: add on tf_idf
rrTokens<-rrTokens %>% bind_tf_idf(word, review_id, n)
rrTokens
```


\# Sentiment analysis using the 3 sentiment dictionaries
```{r message=FALSE, warning=FALSE, cache=TRUE}
#take a look at the words in the sentiment dictionaries
get_sentiments("bing") #%>% view()
```

```{r message=FALSE, warning=FALSE, cache=TRUE, include=FALSE}
get_sentiments("afinn") #%>% view()
```

```{r message=FALSE, warning=FALSE, cache=TRUE, include=FALSE}
#to retain only the words which match the sentiment dictionary, do an inner-join
rrSenti_bing<- rrTokens %>% inner_join( get_sentiments("bing"), by="word")
 
#  Which words contribute to positive/negative sentiment ?
#count the occurrences of positive/negative sentiment words in the reviews
xx<-rrSenti_bing %>% group_by(word, sentiment) %>% summarise(totOcc=sum(n)) %>% arrange(sentiment, desc(totOcc))
xx

xx_neg<-rrSenti_bing %>% group_by(word, sentiment) %>%filter(sentiment=="negative") %>% summarise(totOcc=sum(n)) %>% arrange(sentiment, desc(totOcc))
xx_pos<-rrSenti_bing %>% group_by(word, sentiment) %>%filter(sentiment=="positive") %>% summarise(totOcc=sum(n)) %>% arrange(sentiment, desc(totOcc))

xx_neg
xx_pos

```

# ranked by term importance（ tf*idf = the importance of text）
```{r}
xx<-rrSenti_bing %>% group_by(word, sentiment) %>% summarise(avg=mean(tf_idf),totOcc=sum(n)) %>% arrange(sentiment, desc(avg))
xx

xx_neg_imp<-rrSenti_bing %>% group_by(word, sentiment) %>% filter(sentiment=="negative") %>% summarise(avg=mean(tf_idf),totOcc=sum(n)) %>%   arrange(sentiment, desc(avg))
xx_pos_imp<-rrSenti_bing %>% group_by(word, sentiment) %>% filter(sentiment=="positive") %>% summarise(avg=mean(tf_idf),totOcc=sum(n)) %>%   arrange(sentiment, desc(avg))
 
```



```{r}
# check the number of reviews in different stars Review
xx_senti_star<-rrSenti_bing %>% group_by(starsReview,sentiment) %>%summarise(totOcc=sum(n)) %>% arrange(sentiment, desc(totOcc))

xx_senti_star
resReviewsData %>% group_by(starsReview) %>% count() 
```



# How many matching terms are there for each of the dictionaries?

*For the bing dictionary we found a total of 1130 total matching words*
```{r warning=FALSE}
bingMatchUniqueWords <- unique(rrSenti_bing$word)
str(bingMatchUniqueWords)
```

```{r message=FALSE, warning=FALSE, cache=TRUE}
#negate the counts for the negative sentiment words
xx<- xx %>% mutate (totOcc=ifelse(sentiment=="positive", totOcc, -totOcc))

#the most positive and most negative words
xx<-ungroup(xx)
xx %>% top_n(25) # love /nice	/	delicious/ friendly/ fresh/ pretty
xx %>% top_n(-25) #damn / hell/ ass /	piss /	shit /	wtf /	bad	/ terrible

# check whether are those words really are representative
ws %>% filter(word=='die')
```

```{r message=FALSE, warning=FALSE, cache=TRUE}
#or, with a better reordering of words
rbind(top_n(xx, 20), top_n(xx, -20)) %>% mutate(word=reorder(word,totOcc)) %>% ggplot(aes(word, totOcc, fill=sentiment)) +geom_col()+coord_flip()+ggtitle(" Words Distribution for Positive and Negative_Bing ")
```
# score
```{r message=FALSE, warning=FALSE, cache=TRUE}
#summarise positive/negative sentiment words per review
revSenti_bing <- rrSenti_bing %>% group_by(review_id, starsReview) %>% summarise(nwords=n(),posSum=sum(sentiment=='positive'), negSum=sum(sentiment=='negative'))
```

```{r message=FALSE, warning=FALSE, cache=TRUE}
#calculate sentiment score based on proportion of positive, negative words
revSenti_bing<- revSenti_bing %>% mutate(posProp=posSum/nwords, negProp=negSum/nwords)
revSenti_bing<- revSenti_bing %>% mutate(sentiScore=posProp-negProp)
```
\# agreggation of the scores
```{r message=FALSE, warning=FALSE, cache=TRUE}
# Do review start ratings correspond to the the positive/negative sentiment words
revSenti_bing %>% group_by(starsReview) %>% summarise(avgPos=mean(posProp), avgNeg=mean(negProp), avgSentiSc=mean(sentiScore))
```
### Bing - For Bing the accuracy of prediction is 83.8%
```{r message=FALSE, warning=FALSE, cache=TRUE}

 #consider reviews with 1 to 2 stars as positive, and this with 4 to 5 stars as negative
 revSenti_bing <- revSenti_bing %>% mutate(hiLo=ifelse(starsReview<=2,-1, ifelse(starsReview>=4, 1, 0 )))
 revSenti_bing <- revSenti_bing %>% mutate(pred_hiLo=ifelse(sentiScore >0, 1, -1)) 

 #filter out the reviews with 3 stars, and get the confusion matrix for hiLo vs pred_hiLo
 xx<-revSenti_bing %>% filter(hiLo!=0)
 table(actual=xx$hiLo, predicted=xx$pred_hiLo )

 #accuracy
 BingAccuracy <-mean(xx$hiLo==xx$pred_hiLo)

```




#AFINN
**For the AFINN dictionary we found a total of 622 total matching words**
```{r warning=FALSE}
#AFINN carries a numeric value for positive/negative sentiment -- how would you use these
#rSenti_afinn<-rrTokens %>% inner_join(get_sentiments("afinn"), by="word") %>% summarise(totOcc=sum(n)) %>% arrange(value, desc(totOcc))
rrSenti_afinn<-rrTokens %>% inner_join(get_sentiments("afinn"), by="word") %>% group_by (word, value) %>% summarise(totOcc=sum(n)) %>% arrange(value, desc(totOcc))
rrSenti_afinn

rrSenti_afinn%>% group_by(value) %>% summarise(count=n(), sumn=sum(totOcc))

xx <- rrSenti_afinn %>% mutate(totOcc=ifelse(value > 0, totOcc, -totOcc))

rbind(top_n(xx,25), top_n(xx, -15)) %>% mutate(word=reorder(word,totOcc)) %>% ggplot(aes(word, totOcc, fill=value)) +geom_col()+coord_flip()

AFINNMatchUniqueWords <- unique(rrSenti_afinn$word)
str(AFINNMatchUniqueWords)
```

#### Tried to categorize Afinn score to positive and negative
```{r warning=FALSE}
#Suppose you want   to consider  {anger, disgust, fear sadness, negative} to denote 'bad' reviews, and {positive, joy, anticipation, trust} to denote 'good' reviews
xx<-rrSenti_afinn %>% mutate(goodBad=ifelse(value %in% c('-5', '-4', '-3'), -totOcc, ifelse(value %in% c('5', '4', '3'), totOcc, 0)))
```

```{r warning=FALSE}
xx<-ungroup(xx)
top_n(xx, 50)   # love / nice / excellent / happy / super / perfect / fan / yummy
top_n(xx, -10)  # damn / bad / terrible / horrible / die

ws %>% filter(word=='die') #%>% view()  #use this to check whether the top rank words are really insightful.
```


```{r message=FALSE, warning=FALSE, cache=TRUE}
#with AFINN dictionary words....following similar steps as above, but noting that AFINN assigns negative to positive sentiment value for words matching the dictionary
#take the sum of sentiment value for words in a review?
rrSenti_afinn<- rrTokens %>% inner_join(get_sentiments("afinn"), by="word") %>% mutate(totOcc=sum(n))

rrSenti_afinn <- rrSenti_afinn %>% mutate(goodBad=ifelse(value %in% c('-5', '-4', '-3'), -totOcc, ifelse(value %in% c('5', '4', '3'), totOcc, 0)))
rrSenti_afinn %>% group_by(starsReview) %>% summarise(avgscore=sum(goodBad))  
# 看different star 的 goodBad Score-> 合理！


revSenti_afinn <- rrSenti_afinn %>% group_by(review_id, starsReview) %>% summarise(nwords=n(), sentiSum =sum(value))
revSenti_afinn %>% group_by(starsReview) %>% summarise(avgLen=mean(nwords), avgSenti=mean(sentiSum))
```


Can we classify reviews on high/low stats based on aggregated sentiment of words in the reviews. We can learn a model to predict hiLo ratings, from words in reviews

### Affin - For affin the accuracy of prediction is 84.16%

```{r message=FALSE, warning=FALSE, cache=TRUE}

 #we can consider reviews with 1 to 2 stars as positive, and this with 4 to 5 stars as negative
 revSenti_afinn <- revSenti_afinn %>% mutate(hiLo=ifelse(starsReview<=2,-1, ifelse(starsReview>=4, 1, 0 )))
 revSenti_afinn <- revSenti_afinn %>% mutate(pred_hiLo=ifelse(sentiSum >0, 1, -1)) 
 #filter out the reviews with 3 stars, and get the confusion matrix for hiLo vs pred_hiLo
 xx<-revSenti_afinn %>% filter(hiLo!=0)
 table(actual=xx$hiLo, predicted=xx$pred_hiLo )
 #accuracy
 AffinAccuracy <-mean(xx$hiLo==xx$pred_hiLo)

```



\# Develop models to predict review sentiment. For this, split the data randomly into training and test sets. To make run times manageable, you may take a smaller sample of reviews (minimum should be 10,000).**

\## Bing - Learn a model to predict hiLo ratings, from words in reviews
```{r warning=FALSE}
#use pivot_wider to convert to a dtm form where each row is for a review and columns correspond to words since we want to keep the stars column
revDTM_sentiBing <- rrSenti_bing %>% pivot_wider(id_cols = c(review_id,starsReview), names_from = word, values_from = tf_idf) %>% ungroup()
#Note the ungroup() at the end -- this is IMPORTANT; we have grouped based on (review_id, stars), and this grouping is retained by default, and can cause problems in the later steps
dim(revDTM_sentiBing)
#filter out the reviews with stars=3, and calculate hiLo sentiment 'class'
revDTM_sentiBing <- revDTM_sentiBing %>% filter(starsReview!=3) %>% mutate(hiLo=ifelse(starsReview<=2, -1, 1)) %>% select(-starsReview)
#how many review with 1, -1 'class'
revDTM_sentiBing %>% group_by(hiLo)%>% tally()

set.seed(200)
index <- sample(1:nrow(revDTM_sentiBing), 15000)
index
revDTM_sentiBing_s <- revDTM_sentiBing[index, ]

revDTM_sentiBing_s%>% group_by(hiLo) %>% tally()
```

```{r message=FALSE, warning=FALSE}
library(ranger)
#replace all the NAs with 0
revDTM_sentiBing_s<-revDTM_sentiBing_s %>% replace(., is.na(.), 0)
revDTM_sentiBing_s$hiLo<- as.factor(revDTM_sentiBing_s$hiLo)
```

```{r message=FALSE, warning=FALSE}
library(rsample)
library(ROSE)

set.seed(200)
revDTM_sentiBing_split<- initial_split(revDTM_sentiBing_s, 0.7)
revDTM_sentiBing_trn<- training(revDTM_sentiBing_split)
revDTM_sentiBing_tst<- testing(revDTM_sentiBing_split)
rfModelbing<-ranger(dependent.variable.name = "hiLo", data=revDTM_sentiBing_trn %>% select(-review_id), num.trees = 500, importance='permutation', probability = TRUE)

#which variables are important
rfModelbing
a <- importance(rfModelbing)
sort(a, decreasing = TRUE)

```


```{r warning=FALSE}
#obtain predictions, and calculate performance
revSentiBing_predTrn<- predict(rfModelbing, revDTM_sentiBing_trn %>% select(-review_id))$predictions
revSentiBing_predTst<- predict(rfModelbing, revDTM_sentiBing_tst %>% select(-review_id))$predictions

table(actual=revDTM_sentiBing_trn$hiLo, preds=revSentiBing_predTrn[,2]>0.6197448)  # Accuracy= 0.966
table(actual=revDTM_sentiBing_tst$hiLo, preds=revSentiBing_predTst[,2]>0.6197448)  # Accuracy= 0.87711
```

```{r warning=FALSE}
# accuracy for training
pred = revSentiBing_predTrn[,2]>0.6197448	
pred <- ifelse(pred=="TRUE",1,-1)

rf_bing_acc_trn<-mean(revDTM_sentiBing_trn$hiLo == pred)
rf_bing_acc_trn   #[1] 0.9706667

# accuracy for testing
pred = revSentiBing_predTst[,2]>0.6197448
pred <- ifelse(pred=="TRUE",1,-1)
rf_bing_acc_tst <- mean(revDTM_sentiBing_tst$hiLo == pred)
rf_bing_acc_tst   #0.8904444
```

```{r warning=FALSE}
library(pROC) 
rocTrn <- roc(revDTM_sentiBing_trn$hiLo, revSentiBing_predTrn[,2], levels=c(-1, 1))
rocTst <- roc(revDTM_sentiBing_tst$hiLo, revSentiBing_predTst[,2], levels=c(-1, 1))

#Best threshold from ROC analyses
best_T<-coords(rocTrn, "best", ret="threshold", transpose = FALSE)
best_T #0.6197448	

plot.roc(rocTrn, col='blue', legacy.axes = TRUE)
plot.roc(rocTst, col='red', add=TRUE)
legend("bottomright", legend=c("Training", "Test"),
        col=c("blue", "red"), lwd=2, cex=0.8, bty='n')
```


\# use a broder set of terms
### Define Broader set of terms
\#remove more rare and freq terms
```{r pressure, echo=FALSE}

#tokenize the text of the reviews in the column named 'text‘ - keep only the reviewID, stars attribs 
# STEP 1:  transfer Text -> Words and unnest_tokens(word, text) will by default make text into lowercase
rrTokens_og <- resReviewsData %>% select(review_id, starsReview, text ) %>% unnest_tokens(word, text)
dim(rrTokens_og) #4422210  
head(rrTokens_og)

#How many distinct terms?
rrTokens_og %>% distinct(word) %>% dim() #43993 

# STEP 2: remove stopwords
rrTokens_og <- rrTokens_og %>% anti_join(stop_words)

#count the total occurrences of different words, & sort by most frequent
rrTokens_og %>% count(word, sort=TRUE) %>% top_n(10)
rrTokens_og %>% count(word, sort=TRUE) %>% top_n(-10)

#check distribution of the n : word presents in how may review?
a=rrTokens_og %>% count(word, sort=TRUE) #%>% top_n(-10)
summary(a$n)
 #     Min.  1st Qu.   Median   Mean     3rd Qu.     Max. 
 #    1.00     1.00     2.00    36.32     7.00    32113.00 


# Are there some rare terms, which occur in very few reviews?
# Let's remove the words which are not present in at least 100 reviews
rareWords <-rrTokens_og %>% count(word, sort=TRUE) %>% filter(n<100) 
rareWords
xx<-anti_join(rrTokens_og, rareWords)
xx <- xx %>% filter(str_detect(word,"[0-9]") == FALSE) 
rrTokens_og<- xx
rrTokens_og %>% distinct(word) %>% dim() 
   #[1] 2214  

# remove too frequent words
freqWords <-rrTokens_og %>% count(word, sort=TRUE) %>% filter(n>6000) 
freqWords
xx<-anti_join(rrTokens_og, freqWords)

#confirm that you want these changes
rrTokens_og<- xx
rrTokens_og %>% distinct(word) %>% dim() 
   #[1] 2214  ->  2203  
```


```{r pressure, echo=FALSE}
#frequency
#tokenize, remove stopwords, and lemmatize
rrTokens_og<-rrTokens_og %>% mutate(word = textstem::lemmatize_words(word))

  ##   Or, can tokenize, remove stopwords, lemmatize i as
  #   rrTokens_og <- resReviewsData %>% select(review_id, starsReview, text )%>% unnest_tokens(word, text) %>%        
  #      anti_join(stop_words) %>% mutate(word = textstem::lemmatize_words(word))

# filter out words with less than 3 characters more than 15 characters 
rrTokens_og<-rrTokens_og %>% filter(str_length(word)<=3 | str_length(word)<=15)
rrTokens_og<- rrTokens_og %>% group_by(review_id, starsReview) %>% count(word)

   #count total number of words by review, and add this in a column
   totWords<-rrTokens_og %>% group_by(review_id)%>% count(word, sort=TRUE) %>% summarise(total=sum(n))
   #add the column of counts
   xx<-left_join(rrTokens_og, totWords)
   # now n/total gives the tf values
   xx<- xx %>% mutate(tf=n/total) 
   head(xx)  

#### final touch: add on tf_idf
rrTokens_og<-rrTokens_og %>% bind_tf_idf(word, review_id, n)
rrTokens_og
```



```{r warning=FALSE}
# 用 revDTM 取代 revDTM_sentiBing

revDTM <- rrTokens_og %>%  pivot_wider(id_cols = c(review_id,starsReview), names_from = word, values_from = tf_idf)  
#記住 rrtokens 要有7個 attributes
revDTM <-revDTM %>% filter(starsReview!=3) %>% mutate(hiLo=ifelse(starsReview<=2, -1, 1)) %>% select(-starsReview)
revDTM<-revDTM %>% replace(., is.na(.), 0)


set.seed(200)
index <- sample(1:nrow(revDTM), 15000)
index
revDTM_s <- revDTM[index, ]
revDTM_s%>% group_by(hiLo) %>% tally()

set.seed(200)
revDTM_split<- initial_split(revDTM_s, 0.7)
revDTM_trn_s<- training(revDTM_split)
revDTM_tst_s<- testing(revDTM_split)


rfModel_bro<-ranger(dependent.variable.name = "hiLo", data=revDTM_trn_s %>% select(-review_id), num.trees = 500, importance='permutation', probability = TRUE)

#which variables are important
rfModel_bro
a <- importance(rfModel_bro)
sort(a, decreasing = T)
```


```{r warning=FALSE}
#obtain predictions, and calculate performance
revSenti_predTrn<- predict(rfModel_bro, revDTM_trn_s %>% select(-review_id))$predictions
revSenti_predTst<- predict(rfModel_bro, revDTM_tst_s %>% select(-review_id))$predictions

table(actual=revDTM_trn_s$hiLo, preds=revSenti_predTrn[,2]>0.4795368	)  
table(actual=revDTM_tst_s$hiLo, preds=revSenti_predTst[,2]>0.4795368	)  
```

```{r warning=FALSE}
# accuracy for training
pred = revSenti_predTrn[,2]>0.4795368		
pred <- ifelse(pred=="TRUE",1,-1)

rf_acc_trn<-mean(revDTM_trn_s$hiLo == pred)
rf_acc_trn   #[1] 1

# accuracy for testing
pred = revSenti_predTst[,2]>0.4795368	
pred <- ifelse(pred=="TRUE",1,-1)
rf_acc_tst <- mean(revDTM_tst_s$hiLo == pred)
rf_acc_tst   #0.8822222
```

```{r warning=FALSE}
library(pROC) 
rocTrn_br <- roc(revDTM_trn_s$hiLo, revSenti_predTrn[,2], levels=c(-1, 1))
rocTst_br <- roc(revDTM_tst_s$hiLo, revSenti_predTst[,2], levels=c(-1, 1))

#Best threshold from ROC analyses
best_T<-coords(rocTrn_br, "best", ret="threshold", transpose = FALSE)
best_T #0.4795368	

plot.roc(rocTrn_br, col='blue', legacy.axes = TRUE)
plot.roc(rocTst_br, col='red', add=TRUE)
legend("bottomright", legend=c("Training", "Test"),
        col=c("blue", "red"), lwd=2, cex=0.8, bty='n')
```



\ Develop SVM model for Bing
```{R warning=FALSE}
#develop a SVM model on the sentiment dictionary terms (data=revDTM_sentiBing_trn)
library(e1071)
svmBing <- svm(as.factor(hiLo) ~., data = revDTM_sentiBing_trn %>%select(-review_id),
kernel="radial", cost=1, scale=FALSE) 
revDTM_predTrn_svm1Bing<-predict(svmBing, revDTM_sentiBing_trn)
revDTM_predTst_svm1Bing<-predict(svmBing, revDTM_sentiBing_tst)

table(actual= revDTM_sentiBing_trn$hiLo, predicted= revDTM_predTrn_svm1Bing)
table(actual= revDTM_sentiBing_tst$hiLo, predicted= revDTM_predTst_svm1Bing)

svm_bing_acc_tr_1 <- mean(revDTM_sentiBing_trn$hiLo == revDTM_predTrn_svm1Bing) # [1] 0.754
svm_bing_acc_ts_2 <- mean(revDTM_sentiBing_tst$hiLo == revDTM_predTst_svm1Bing) # [1] 0.7422222
```

```{R eval=FALSE, warning=FALSE, include=FALSE}
# try different parameters -- rbf kernel gamma, and cost

svmBing2 <- svm(as.factor(hiLo) ~., data = revDTM_sentiBing_trn %>% select(-review_id), kernel="radial", cost=5, gamma=5, scale=FALSE)

system.time( svmBing2 <- svm(as.factor(hiLo) ~., data = revDTM_sentiBing_trn
%>% select(-review_id), kernel="radial", cost=5, gamma=5, scale=FALSE) )

# 

 revDTM_predTrn_svm2Bing<-predict(svmBing2, revDTM_sentiBing_trn)
 table(actual= revDTM_sentiBing_trn$hiLo, predicted= revDTM_predTrn_svm2Bing)
 revDTM_predTst_svm2Bing<-predict(svmBing2, revDTM_sentiBing_tst)
 table(actual= revDTM_sentiBing_tst$hiLo, predicted= revDTM_predTst_svm2Bing)

 svm_bing_acc_tr <- mean(revDTM_sentiBing_trn$hiLo == revDTM_predTrn_svm2Bing) # 0.9728571 UP!
 svm_bing_acc_ts <- mean(revDTM_sentiBing_tst$hiLo == revDTM_predTst_svm2Bing) # 0.8824444
 
```

\#ROC_SVM_BING
```{r warning=FALSE}
library(ROCR)
revDTM_predTrn_svm2Bing<- predict(svmBing2,revDTM_sentiBing_trn)
pr1<-prediction(as.numeric(revDTM_predTrn_svm2Bing), as.numeric(revDTM_sentiBing_trn$hiLo))
prf1<- performance(pr1, measure="tpr",x.measure="fpr")
plot(prf1)
lines(x = c(0,1), y = c(0,1),col="blue")

revDTM_predTst_svm2Bing<- predict(svmBing2,revDTM_predTst_svm2Bing)
pr<-prediction(as.numeric(revDTM_predTst_svm2Bing), as.numeric(revDTM_sentiBing_tst$hiLo))
prf<- performance(pr, measure="tpr",x.measure="fpr")

plot(prf1, col='blue', legacy.axes = TRUE)
plot(prf,col='red', add=TRUE)
lines(x = c(0,1), y = c(0,1),col="black")
legend("bottomright", legend=c("Training", "Testing"),
        col=c("blue", "red"), lwd=2, cex=0.8, bty='n')

```


\#(d) Define Broader set of terms
\#remove more rare and freq terms
```{r pressure, echo=FALSE}

#tokenize the text of the reviews in the column named 'text‘ - keep only the reviewID, stars attribs 
# STEP 1:  transfer Text -> Words and unnest_tokens(word, text) will by default make text into lowercase
rrTokens_og <- resReviewsData %>% select(review_id, starsReview, text ) %>% unnest_tokens(word, text)
dim(rrTokens_og) #4422210  
head(rrTokens_og)

rrTokens_og <- rrTokens_og %>% anti_join(stop_words)

rareWords <-rrTokens_og %>% count(word, sort=TRUE) %>% filter(n<100) 
rareWords

# remove rare words from rrtokens
xx<-anti_join(rrTokens_og, rareWords)

xx %>% count(word, sort=TRUE) %>% view()
xx <- xx %>% filter(str_detect(word,"[0-9]") == FALSE) 
xx %>% count(word, sort=TRUE) %>% view() #check again
#confirm that you want these changes
rrTokens_og<- xx
#How many distinct tokens remain ?
rrTokens_og %>% distinct(word) %>% dim() 
   #[1] 2214  

freqWords <-rrTokens_og %>% count(word, sort=TRUE) %>% filter(n>6000) 
freqWords

# remove frequent words from rrtokens
xx<-anti_join(rrTokens_og, freqWords)

#confirm that you want these changes
rrTokens_og<- xx
#How many distinct tokens remain ? 
rrTokens_og %>% distinct(word) %>% dim() 
   #[1] 2214  ->  2203  
```


```{r pressure, echo=FALSE}
#frequency
#tokenize, remove stopwords, and lemmatize
rrTokens_og<-rrTokens_og %>% mutate(word = textstem::lemmatize_words(word))
# filter out words with less than 3 characters more than 15 characters 
rrTokens_og<-rrTokens_og %>% filter(str_length(word)<=3 | str_length(word)<=15)

rrTokens_og<- rrTokens_og %>% group_by(review_id, starsReview) %>% count(word)

   #count total number of words by review, and add this in a column
   totWords<-rrTokens_og %>% group_by(review_id)%>% count(word, sort=TRUE) %>% summarise(total=sum(n))
   #add the column of counts
   xx<-left_join(rrTokens_og, totWords)
   # now n/total gives the tf values
   xx<- xx %>% mutate(tf=n/total) 
   head(xx)  

#### final touch: add on tf_idf
rrTokens_og<-rrTokens_og %>% bind_tf_idf(word, review_id, n)
rrTokens_og
```


```{r pressure, echo=FALSE}
revDTM <- rrTokens_og %>%  pivot_wider(id_cols = c(review_id,starsReview), names_from = word, values_from = tf_idf)  #記住 rrtokens 要有7個 attributes
revDTM <-revDTM %>% filter(starsReview!=3) %>% mutate(hiLo=ifelse(starsReview<=2, -1, 1)) %>% select(-starsReview)
revDTM<-revDTM %>% replace(., is.na(.), 0)


set.seed(200)
index <- sample(1:nrow(revDTM), 15000)
index
revDTM_s <- revDTM[index, ]
revDTM_s%>% group_by(hiLo) %>% tally()

set.seed(200)
revDTM_split<- initial_split(revDTM_s, 0.7)
revDTM_trn_s<- training(revDTM_split)
revDTM_tst_s<- testing(revDTM_split)
```


## Develop SVM model on broader set of terms
```{r}
#develop a SVM model on the sentiment dictionary terms (data=revDTM_trn_s)

svmM1_b <- svm(as.factor(hiLo) ~., data = revDTM_trn_s %>%select(-review_id),kernel="radial", cost=1, scale=FALSE) 

revDTM_predTrn_svm1broad<-predict(svmM1_b, revDTM_trn_s)
revDTM_predTst_svm1broad<-predict(svmM1_b, revDTM_tst_s)  
 # showing error:predict.svm(svmM2broad, revDTM_tst_s)：test data does not match model !
  #str(revDTM_trn_s)
  #str(revDTM_tst_s)

table(actual= revDTM_trn_s$hiLo, predicted= revDTM_predTrn_svm1broad)
table(actual= revDTM_tst_s$hiLo, predicted= revDTM_predTst_svm1broad)

svm_bing_acc_tr_b <- mean(revDTM_trn_s$hiLo == revDTM_predTrn_svm1broad) 
```

```{r eval=FALSE, warning=FALSE, include=FALSE}
# try different parameters -- rbf kernel gamma, and cost
system.time( svmM2broad <- svm(as.factor(hiLo) ~., data = revDTM_trn_s%>% select(-review_id), kernel="radial", cost=5, gamma=5, scale=FALSE) )

revDTM_predTrn_svm2<-predict(svmM2broad, revDTM_trn_s)
table(actual= revDTM_trn_s$hiLo, predicted= revDTM_predTrn_svm2)
revDTM_predTst_svm2<-predict(svmM2broad, revDTM_tst_s)
table(actual= revDTM_tst_s$hiLo, predicted= revDTM_predTst_svm2)
svm_acc_tr <- mean(revDTM_trn_s$hiLo == revDTM_predTrn_svm2) 
svm_acc_ts <- mean(revDTM_tst_s$hiLo == revDTM_predTst_svm2) 
```



\#let's look at attributes that characterize different restaurant, do restaurant with certain characteristic has stronger reviews? Are pedictios betrer with certain characteristic?
```{r}

# RF model: rfModelbing
# SVM: svmBing2

rrData <- resReviewsData %>% filter(str_detect(postal_code, "^[0-9]{1,5}"))
x<- rrData %>% select (review_id, attributes,)
paste(x[1,2]) # take a look at 第一個review的第二欄
x2<-x %>% mutate (atts = str_split( attributes, '\\|')) %>% unnest(atts)
x3<- x2 %>% cbind( str_split_fixed ( x2$atts, ":", 2) ) 
colnames(x3)[4]<- 'attName'
colnames(x3)[5]<- 'attValue'
x3<-x3 %>% select (-c (attributes ,atts))
x3<-x3[!(is.na(x3$attName) | x3$attName==""), ] 
x4<- x3 %>% pivot_wider( names_from = attName, values_from = attValue)
  # Column 36 must be named.
 # Use .name_repair to specify repair.    ADD on x3<-x3[!(is.na(x3$attName) | x3$attName==""), ] 


xxx <- resReviewsData %>% select(c(review_id,starsReview,starsBusiness))

x4_full<-x4 %>% left_join(xxx)

x4_full %>% group_by(Alcohol,starsReview) %>% tally()
x4_full %>% group_by(Alcohol) %>% summarise(avgStar=mean(starsReview))

# GoodForKids
x4_full %>% group_by(GoodForKids) %>% summarise(avgStar=mean(starsReview), avgBusStar=mean(starsBusiness)) 
x4_full %>% group_by(GoodForKids) %>% tally()
glimpse(x4_full)

#Restaurants Reservations
x4_full %>% group_by(RestaurantsReservations) %>% summarise(avgStar=mean(starsReview), avgBusStar=mean(starsBusiness)) 
x4_full %>% group_by(RestaurantsReservations) %>% tally()
glimpse(x4_full)


```


\# add on accuracy
```{r}
# eg: group_by(Alocohol) %>% summarise(accuracy)

view(x4_full)

GforKid_t <- x4_full %>%  select(c(review_id),GoodForKids) %>% filter(GoodForKids==" True" ) 
GforKid_t <-GforKid_t %>%  select(-c(GoodForKids))
GforKid_t <- GforKid_t %>% left_join(revDTM_sentiBing)

GforKid_f <- x4_full %>%  select(c(review_id),GoodForKids) %>% filter(GoodForKids==" False" ) 
GforKid_f <-GforKid_f %>%  select(-c(GoodForKids))
GforKid_f <- GforKid_f %>% left_join(revDTM_sentiBing)



RReserve_t <- x4_full %>%  select(c(review_id),RestaurantsReservations) %>% filter(RestaurantsReservations==" True" ) 
RReserve_t <-RReserve_t %>%  select(-c(RestaurantsReservations))
RReserve_t <- RReserve_t %>% left_join(revDTM_sentiBing)

RReserve_f <- x4_full %>%  select(c(review_id),RestaurantsReservations) %>% filter(RestaurantsReservations==" False" ) 
RReserve_f <-RReserve_f %>%  select(-c(RestaurantsReservations))
RReserve_f <- RReserve_f %>% left_join(revDTM_sentiBing)



```


\# Good For Kids
\# use Bing
```{r pressure, echo=FALSE}
install.packages("doParallel")
library(doParallel)
registerDoParallel(4)


# H E R E
GforKid_t <-GforKid_t %>% filter(starsReview!=3) %>% mutate(hiLo=ifelse(starsReview<=2, -1, 1)) %>% select(-starsReview)
GforKid_t<-GforKid_t %>% replace(., is.na(.), 0)

GforKid_f <-GforKid_f %>% filter(starsReview!=3) %>% mutate(hiLo=ifelse(starsReview<=2, -1, 1)) %>% select(-starsReview)
GforKid_f<-GforKid_f %>% replace(., is.na(.), 0)



library(rsample)
library(ROSE)

set.seed(200)
index <- sample(1:nrow(GforKid_t), 15000)
index
GforKid_t <- GforKid_t[index, ]
GforKid_t%>% group_by(hiLo) %>% tally()

set.seed(200)
revDTM_split_gfk<- initial_split(GforKid_t, 0.7)
revDTM_trn_gfk<- training(revDTM_split_gfk)
revDTM_tst_gfk<- testing(revDTM_split_gfk)


set.seed(200)
index <- sample(1:nrow(GforKid_f), 7000)
index
GforKid_f <- GforKid_f[index, ]
GforKid_f%>% group_by(hiLo) %>% tally()

set.seed(200)
revDTM_split_gfk_f<- initial_split(GforKid_f, 0.7)
revDTM_trn_gfk_f<- training(revDTM_split_gfk_f)
revDTM_tst_gfk_f<- testing(revDTM_split_gfk_f)
```

```{r}
library(ranger)

rfModelgfk<-ranger(dependent.variable.name = "hiLo", data=revDTM_trn_gfk %>% select(-review_id), num.trees = 500, importance='permutation', probability = TRUE)

rfModelgfk_f<-ranger(dependent.variable.name = "hiLo", data=revDTM_trn_gfk_f %>% select(-review_id), num.trees = 500, importance='permutation', probability = TRUE)

```


```{r warning=FALSE}
#obtain predictions, and calculate performance
revBing_predTrn_gfk<- predict(rfModelgfk, revDTM_trn_gfk %>% select(-review_id))$predictions
revBing_predTst_gfk<- predict(rfModelgfk, revDTM_tst_gfk %>% select(-review_id))$predictions

table(actual=revDTM_trn_gfk$hiLo, preds=revBing_predTrn_gfk[,1]>0.6244062)  
table(actual=revDTM_tst_gfk$hiLo, preds=revBing_predTst_gfk[,1]>0.6244062)  

revBing_predTrn_gfk_f<- predict(rfModelgfk_f, revDTM_trn_gfk_f %>% select(-review_id))$predictions
revBing_predTst_gfk_f<- predict(rfModelgfk_f, revDTM_tst_gfk_f %>% select(-review_id))$predictions

table(actual=revDTM_trn_gfk$hiLo, preds=revBing_predTrn_gfk[,1]>0.6282966)  
table(actual=revDTM_tst_gfk$hiLo, preds=revBing_predTst_gfk[,1]>0.6282966)  
```

\# GfK Accuracy
```{r warning=FALSE}
# accuracy for training
pred = revBing_predTrn_gfk[,1]>0.6244062  	  			
	
pred <- ifelse(pred=="TRUE",1,-1)

rf_bing_acc_trn<-mean(revDTM_trn_gfk$hiLo == pred)
rf_bing_acc_trn   #[1] 0.9671429

# accuracy for testing
pred = revBing_predTst_gfk[,1]>0.6244062				

pred <- ifelse(pred=="TRUE",1,-1)
rf_bing_acc_tst <- mean(revDTM_tst_gfk$hiLo == pred)
rf_bing_acc_tst   #0.8851111



#accuracy for training
pred = revBing_predTrn_gfk_f[,1]>0.6282966				
	
pred <- ifelse(pred=="TRUE",1,-1)

rf_bing_acc_trn_f<-mean(revDTM_trn_gfk_f$hiLo == pred)
rf_bing_acc_trn_f   #[1] 0.9755102

# accuracy for testing
pred = revBing_predTst_gfk_f[,1]>0.6282966				

pred <- ifelse(pred=="TRUE",1,-1)
rf_bing_acc_tst_f <- mean(revDTM_tst_gfk_f$hiLo == pred)
rf_bing_acc_tst   #0.8811111
```

```{r warning=FALSE}
library(pROC) 
rocTrn <- roc(revDTM_trn_gfk$hiLo, revBing_predTrn_gfk[,1], levels=c(-1, 1))
rocTst <- roc(revDTM_tst_gfk$hiLo, revBing_predTst_gfk[,1], levels=c(-1, 1))

#Best threshold from ROC analyses
best_T<-coords(rocTrn, "best", ret="threshold", transpose = FALSE)
best_T #0.6244062  	

plot.roc(rocTrn, col='blue', legacy.axes = TRUE)
plot.roc(rocTst, col='red', add=TRUE)
legend("bottomright", legend=c("Training", "Test"),
        col=c("blue", "red"), lwd=2, cex=0.8, bty='n')


rocTrn_f <- roc(revDTM_trn_gfk_f$hiLo, revBing_predTrn_gfk_f[,1], levels=c(-1, 1))
rocTst_f <- roc(revDTM_tst_gfk_f$hiLo, revBing_predTst_gfk_f[,1], levels=c(-1, 1))

#Best threshold from ROC analyses
best_T_f<-coords(rocTrn_f, "best", ret="threshold", transpose = FALSE)
best_T_f #0.6282966	

plot.roc(rocTrn_f, col='blue', legacy.axes = TRUE)
plot.roc(rocTst_f, col='red', add=TRUE)
legend("bottomright", legend=c("Training", "Test"),
        col=c("blue", "red"), lwd=2, cex=0.8, bty='n')
```


\# Restaurants Reservations or not
\# Use Bing
```{r pressure, echo=FALSE}
install.packages("doParallel")
library(doParallel)
registerDoParallel(4)


# H E R E
RReserve_t <-RReserve_t %>% filter(starsReview!=3) %>% mutate(hiLo=ifelse(starsReview<=2, -1, 1)) %>% select(-starsReview)
RReserve_t<-RReserve_t %>% replace(., is.na(.), 0)

RReserve_f <-RReserve_f %>% filter(starsReview!=3) %>% mutate(hiLo=ifelse(starsReview<=2, -1, 1)) %>% select(-starsReview)
RReserve_f<-RReserve_f %>% replace(., is.na(.), 0)



library(rsample)
library(ROSE)

set.seed(200)
index <- sample(1:nrow(RReserve_t), 15000)
index
RReserve_t <- RReserve_t[index, ]
RReserve_t%>% group_by(hiLo) %>% tally()

set.seed(200)
revDTM_split_rr<- initial_split(RReserve_t, 0.7)
revDTM_trn_rr<- training(revDTM_split_rr)
revDTM_tst_rr<- testing(revDTM_split_rr)


set.seed(200)
index <- sample(1:nrow(RReserve_f), 7000)
index
RReserve_f <- RReserve_f[index, ]
RReserve_f%>% group_by(hiLo) %>% tally()

set.seed(200)
revDTM_split_rr_f<- initial_split(RReserve_f, 0.7)
revDTM_trn_rr_f<- training(revDTM_split_rr_f)
revDTM_tst_rr_f<- testing(revDTM_split_rr_f)
```


```{r}

library(ranger)

rfModelrr<-ranger(dependent.variable.name = "hiLo", data=revDTM_trn_rr %>% select(-review_id), num.trees = 500, importance='permutation', probability = TRUE)

rfModelrr_f<-ranger(dependent.variable.name = "hiLo", data=revDTM_trn_rr_f %>% select(-review_id), num.trees = 500, importance='permutation', probability = TRUE)

```


```{r warning=FALSE}
#obtain predictions, and calculate performance
revBing_predTrn_rr<- predict(rfModelrr, revDTM_trn_rr %>% select(-review_id))$predictions
revBing_predTst_rr<- predict(rfModelrr, revDTM_tst_rr %>% select(-review_id))$predictions

table(actual=revDTM_trn_rr$hiLo, preds=revBing_predTrn_rr[,1]>0.6459355)  
table(actual=revDTM_trn_rr_f$hiLo, preds=revBing_predTst_rr[,1]>0.6459355)  

revBing_predTrn_rr_f<- predict(rfModelrr_f, revDTM_trn_rr_f %>% select(-review_id))$predictions
revBing_predTst_rr_f<- predict(rfModelrr_f, revDTM_tst_rr_f %>% select(-review_id))$predictions

table(actual=revDTM_trn_rr$hiLo, preds=revBing_predTrn_rr_f[,1]>0.5888654)  
table(actual=revDTM_trn_rr_f$hiLo, preds=revBing_predTst_rr_f[,1]>0.5888654)  
```

\# Accuracy for Restaurants Reservations
```{r warning=FALSE}
# accuracy for training
pred = revBing_predTrn_rr[,1]>0.6459355  	  			
pred <- ifelse(pred=="TRUE",1,-1)
rf_bing_acc_trn<-mean(revDTM_trn_rr$hiLo == pred)
rf_bing_acc_trn   #[1] 0.9729524

# accuracy for testing
pred = revBing_predTst_rr[,1]>0.6459355				
pred <- ifelse(pred=="TRUE",1,-1)
rf_bing_acc_tst <- mean(revDTM_tst_rr$hiLo == pred)
rf_bing_acc_tst   #0.8882222



#accuracy for training
pred = revBing_predTrn_rr_f[,1]>0.5888654				
pred <- ifelse(pred=="TRUE",1,-1)
rf_bing_acc_trn_f<-mean(revDTM_trn_rr_f$hiLo == pred)
rf_bing_acc_trn_f   #[1] 0.9712245

# accuracy for testing
pred = revBing_predTst_rr_f[,1]>0.5888654				
pred <- ifelse(pred=="TRUE",1,-1)
rf_bing_acc_tst_f <- mean(revDTM_tst_rr_f$hiLo == pred)
rf_bing_acc_tst_f   #0.8738095
```

```{r warning=FALSE}
library(pROC) 
rocTrn <- roc(revDTM_trn_rr$hiLo, revBing_predTrn_rr[,1], levels=c(-1, 1))
rocTst <- roc(revDTM_tst_rr$hiLo, revBing_predTst_rr[,1], levels=c(-1, 1))

#Best threshold from ROC analyses
best_T<-coords(rocTrn, "best", ret="threshold", transpose = FALSE)
best_T #0.6459355  	

plot.roc(rocTrn, col='blue', legacy.axes = TRUE)
plot.roc(rocTst, col='red', add=TRUE)
legend("bottomright", legend=c("Training", "Test"),
        col=c("blue", "red"), lwd=2, cex=0.8, bty='n')


rocTrn_f <- roc(revDTM_trn_rr_f$hiLo, revBing_predTrn_rr_f[,1], levels=c(-1, 1))
rocTst_f <- roc(revDTM_tst_rr_f$hiLo, revBing_predTst_rr_f[,1], levels=c(-1, 1))

#Best threshold from ROC analyses
best_T_f<-coords(rocTrn_f, "best", ret="threshold", transpose = FALSE)
best_T_f #0.5888654	

plot.roc(rocTrn_f, col='blue', legacy.axes = TRUE)
plot.roc(rocTst_f, col='red', add=TRUE)
legend("bottomright", legend=c("Training", "Test"),
        col=c("blue", "red"), lwd=2, cex=0.8, bty='n')
```

####  take a deeper look into Ambience
```{r}
paste(x4[1,3])
x5 <- x4 %>% mutate( amb = str_split( Ambience, ","))

extractAmbience <- function(q) {sub(":.*","", q[which(str_extract(q, "True") == "True")]) }

x6<- x5 %>% mutate( amb = lapply( amb, extractAmbience ) )
x6 %>% group_by(amb) %>% tally() %>% view()
x6$amb
```


### take a deeper look into GoodforMeal
```{r}
paste(x4[1,5])
x7 <- x4 %>% mutate( GforM = str_split( GoodForMeal, ","))

extractAmbience <- function(q) {sub(":.*","", q[which(str_extract(q, "True") == "True")]) }

x7<- x7 %>% mutate( GforM = lapply( GforM, extractAmbience ) )
x7 %>% group_by(GforM) %>% tally() %>% view()
x7$GforM
```



################## Text Mining completed #########################

























